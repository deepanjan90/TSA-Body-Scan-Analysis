{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### keras supports multi GPU for tensorflow 1.4 but the only missing function which cause conflicts is \n",
    "#### tf.Session.sess.list_devices()\n",
    "#### Making a dummy here\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "\n",
    "def get_local_devices():\n",
    "    local_devices = device_lib.list_local_devices()\n",
    "    for device in local_devices:\n",
    "        device.name = device.name.replace('/', 'device:')\n",
    "    return local_devices\n",
    "\n",
    "sess = K.get_session()\n",
    "sess.list_devices = get_local_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import threading\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Maximum\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import exploratory_model.tsahelper as tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "DATASET_PATH = \"../../dataset/preprocessed-a3daps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    print('decorating')\n",
    "    def g(*a, **kw):\n",
    "        print('thread safing')\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sublect_list = os.listdir(DATASET_PATH)\n",
    "np.random.shuffle(sublect_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FREEZE_LAYERS = 18\n",
    "INPUT_SHAPE = (660, 660, 3)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    base_model = VGG16(include_top=False, input_shape=INPUT_SHAPE, pooling='None', weights='imagenet')\n",
    "    layer_1 = base_model.layers[1]\n",
    "    block1_conv1_weight = layer_1.get_weights()\n",
    "\n",
    "    x = None\n",
    "    inputs = []\n",
    "    new_layer_1 = []\n",
    "    for i in range(4):\n",
    "        x = Input(shape=INPUT_SHAPE, name=('input_' + str(i+1)))\n",
    "        inputs.append(x)\n",
    "        x = type(layer_1)(\n",
    "                filters=layer_1.filters,\n",
    "                strides=layer_1.strides,\n",
    "                kernel_size=layer_1.kernel_size,\n",
    "                activation=layer_1.activation,\n",
    "                weights=block1_conv1_weight\n",
    "            )(x)\n",
    "        new_layer_1.append(x)\n",
    "\n",
    "    x = Maximum()(new_layer_1)\n",
    "\n",
    "    for layer in base_model.layers[2:]:\n",
    "        if type(layer) == MaxPooling2D:\n",
    "            x = type(layer)(\n",
    "                    pool_size=layer.pool_size,\n",
    "                    strides=layer.strides,\n",
    "                    padding=layer.padding,\n",
    "                    data_format=layer.data_format\n",
    "                )(x)\n",
    "        elif type(layer) == Conv2D:\n",
    "            x = type(layer)(\n",
    "                    filters=layer.filters,\n",
    "                    strides=layer.strides,\n",
    "                    kernel_size=layer.kernel_size,\n",
    "                    activation=layer.activation,\n",
    "                    weights=layer.get_weights()\n",
    "                )(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # # let's add a fully-connected layer\n",
    "    x = Dense(4096, activation='relu', kernel_initializer='truncated_normal', bias_initializer='random_uniform')(x)\n",
    "    x = Dense(4096, activation='relu', kernel_initializer='truncated_normal', bias_initializer='random_uniform')(x)\n",
    "\n",
    "    # # and a logistic layer, activation=sigmoid since we have multi label classification\n",
    "    predictions = Dense(17, activation='sigmoid', kernel_initializer='truncated_normal',\n",
    "                        bias_initializer='random_uniform', name='output')(x)\n",
    "\n",
    "    # # this is the model we will train\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    # # Freeze first FREEZE_LAYERS in the model\n",
    "    for layer in model.layers[:FREEZE_LAYERS]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Learning rate is changed to 0.001 = 1/10 of actual vgg16 since we are fine tuning\n",
    "model = multi_gpu_model(model, gpus=4)\n",
    "# sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# # loss=binary_crossentropy for sigmoid unitsfrom keras import backend as K\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(image):\n",
    "    X = []\n",
    "    image[image<0]=0\n",
    "    image = np.pad(image, ((0,0), (74,74)), 'edge')\n",
    "    image = image.reshape((660,660,1))\n",
    "    image = np.repeat(image, 3, axis=2)\n",
    "    X.append(image)\n",
    "    image = np.rot90(image)\n",
    "    X.append(image)\n",
    "    image = np.rot90(image)\n",
    "    X.append(image)\n",
    "    image = np.rot90(image)\n",
    "    X.append(image)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.8\n",
    "sublect_list = os.listdir(DATASET_PATH)\n",
    "file_list = sublect_list\n",
    "number_of_train = int(len(file_list)*TRAIN_TEST_SPLIT)\n",
    "TRAIN_SET_FILE_LIST = file_list[:number_of_train]\n",
    "TEST_SET_FILE_LIST = file_list[number_of_train:]\n",
    "\n",
    "def get_io_tensors(in_size):\n",
    "    return [[] for i in range(in_size)], []\n",
    "\n",
    "@threadsafe_generator\n",
    "def data_generator(subject_file_list, in_size, batch_size):\n",
    "    print(\"Generator Initiated\")\n",
    "    in_tensor, out_tensor = get_io_tensors(in_size)\n",
    "    counter = 0\n",
    "    batch_number = 0\n",
    "    for subject_image in subject_file_list:            \n",
    "        npset = np.load(os.path.join(DATASET_PATH, subject_image))\n",
    "        images = np.array(npset[0], dtype=np.float32)\n",
    "        labels = np.array([i[1] for i in npset[1]], dtype=np.float32)\n",
    "#         images = np.zeros((64, 660, 512), dtype=np.float32)\n",
    "#         labels = np.zeros(17, dtype=np.float32)\n",
    "        \n",
    "        for i in range(16):\n",
    "            # Containes four angle each with 4 augmentations\n",
    "            input_augments = []\n",
    "            for j in range(4):\n",
    "                input_augments.append(augment(images[i + j*16]))\n",
    "\n",
    "            for j in range(4):\n",
    "                for in_i in range(in_size):\n",
    "                    in_tensor[in_i].append(input_augments[in_i][j])\n",
    "                out_tensor.append(labels)\n",
    "                \n",
    "                counter += 1\n",
    "                if counter >= batch_size:\n",
    "                    for in_i in range(in_size):\n",
    "                        in_tensor[in_i] = np.array(in_tensor[in_i])\n",
    "                    out_tensor = np.array(out_tensor)\n",
    "#                     print(\"Yielding batch \", batch_number, \"Size\", len(in_tensor))\n",
    "                    yield(in_tensor, out_tensor)\n",
    "                    counter = counter%batch_size\n",
    "                    batch_number += 1\n",
    "                    in_tensor, out_tensor = get_io_tensors(in_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unit Test\n",
    "\n",
    "# t = data_generator(TRAIN_SET_FILE_LIST, 4, 64)\n",
    "\n",
    "# fig, ax = plt.subplots(4,4,figsize=(16,16))\n",
    "# row = 0\n",
    "# col = 0\n",
    "\n",
    "# for in_tensors, out_tensors in t:\n",
    "#     print('out', out_tensors.shape)\n",
    "#     print(in_tensors[0].shape)\n",
    "\n",
    "#     col = 0\n",
    "#     for tensor in in_tensors:\n",
    "#         ax[row, col].imshow(tensor[row])\n",
    "#         col += 1\n",
    "#     row += 1\n",
    "#     if row == 4:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_images = 917 * 16 * 2 * 2\n",
    "batch_size = 4\n",
    "step_per_epoch = 16\n",
    "epochs = 917\n",
    "in_size = len(inputs)\n",
    "\n",
    "model.fit_generator(\n",
    "    data_generator(TRAIN_SET_FILE_LIST, in_size, batch_size), step_per_epoch, epochs, verbose=2,\n",
    "    use_multiprocessing=True, shuffle=True, initial_epoch=0, max_queue_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "# model.fit(X_train, y_train, epochs=5, batch_size=2000)\n",
    "\n",
    "# preds = model.predict(X_test)\n",
    "# preds[preds>=0.5] = 1\n",
    "# preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
